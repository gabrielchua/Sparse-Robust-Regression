{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e947145-51a2-4577-9cd0-f5524f3cfb6d",
   "metadata": {},
   "source": [
    "# 2023-09-23 Demo: Machine Learning and Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45991898-a488-4414-b79a-2fe0949d1841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install pyomo and amply\n",
    "!pip install -q pyomo amplpy pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c02f1562-5bae-4f00-9d45-68bfc06b8cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Initialize AMPL \n",
    "# from amplpy import AMPL, tools\n",
    "\n",
    "# ampl = tools.ampl_notebook(\n",
    "#     modules=[\"coin\", \"highs\", \"gokestrel\"], # modules to install\n",
    "#     g=globals()) # instantiate AMPL object and register magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d87fbc-caef-478b-b7de-2ca15b792383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from amplpy import modules\n",
    "import pyomo.environ as pyo\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a154d00-39de-4dd7-a516-d372c72b9024",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b20eba-e91e-4cf3-8e57-1ebd4111d070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a133c138-c4b0-4dcd-9bf5-3b47eb606002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def solver_regression(X, y, solver, fit_intercept=True):\n",
    "    \n",
    "    # Intialise the solver\n",
    "    solver = pyo.SolverFactory(modules.find(solver), solve_io=\"nl\")\n",
    "\n",
    "    # Set dimensions of dataset\n",
    "    N, d = X.shape\n",
    "\n",
    "    if fit_intercept:\n",
    "        # Add another column of constants to be the bias/intercept term\n",
    "        X_bias = np.hstack([np.ones((N, 1)), X])\n",
    "\n",
    "    # Initialize Optimisation Model\n",
    "    model = pyo.ConcreteModel()\n",
    "\n",
    "    # Define decision variables (linear regression coefficients and intercept)\n",
    "    model.w = pyo.Var(range(d+1), domain=pyo.Reals)\n",
    "\n",
    "    # Objective\n",
    "    model.obj = pyo.Objective(\n",
    "        expr=sum((y[i] - sum(X_bias[i, j] * model.w[j] for j in range(d+1)))**2 for i in range(N)),\n",
    "        sense=pyo.minimize\n",
    "    )\n",
    "    \n",
    "    # Solve the model\n",
    "    results = solver.solve(model)\n",
    "    \n",
    "    # Print the results\n",
    "    if results.solver.status == pyo.SolverStatus.ok and results.solver.termination_condition == pyo.TerminationCondition.optimal:\n",
    "        # Extracting coefficients\n",
    "        coefficients = [round(model.w[i].value, 2) for i in range(d+1)]\n",
    "\n",
    "        print(\"Solved! ðŸŽ‰\")\n",
    "        print(\"Solver Coefficients:\", coefficients)\n",
    "\n",
    "        # Print regression formula\n",
    "        formula = \"y = {}\".format(coefficients[0]) + \" + \"  + \" + \".join(\"{}*x{}\".format(coeff, idx) for idx, coeff in enumerate(coefficients[1:], 1))\n",
    "        print(\"Regression Formula:\", formula)\n",
    "\n",
    "    else:\n",
    "        print(\"Solver did not converge!\")\n",
    "\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a974de20-b9bc-4138-8c55-03bc43eecf27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved! ðŸŽ‰\n",
      "Solver Coefficients: [152.13, -10.01, -239.82, 519.85, 324.38, -792.18, 476.74, 101.04, 177.06, 751.27, 67.63]\n",
      "Regression Formula: y = 152.13 + -10.01*x1 + -239.82*x2 + 519.85*x3 + 324.38*x4 + -792.18*x5 + 476.74*x6 + 101.04*x7 + 177.06*x8 + 751.27*x9 + 67.63*x10\n"
     ]
    }
   ],
   "source": [
    "solver_coeffs = solver_regression(X, y, \"ipopt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e48e4a-005d-4bc0-b66c-566747f30a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scikit-learn Coefficients: [152.13, -10.01, -239.82, 519.85, 324.38, -792.18, 476.74, 101.04, 177.06, 751.27, 67.63]\n"
     ]
    }
   ],
   "source": [
    "# Fit regression model using scikit-learn for comparison\n",
    "reg = LinearRegression(fit_intercept=True)\n",
    "reg.fit(X, y)\n",
    "sklearn_coeffs = [round(reg.intercept_, 2)] + [round(coef, 2) for coef in reg.coef_]\n",
    "print(\"\\nScikit-learn Coefficients:\", sklearn_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37f2461d-55ae-48be-a420-6e52d388b928",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(solver_coeffs == sklearn_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60888078-0db1-4642-a39f-14f2951ca903",
   "metadata": {},
   "source": [
    "# Model 2: Robust Linear Regression (add L2 ridge penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e65ccceb-f5f3-476a-b084-354316677081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def solver_ridge(X, y, solver, alpha=1, fit_intercept=True):\n",
    "\n",
    "    # Intialise the solver\n",
    "    solver = pyo.SolverFactory(modules.find(solver), solve_io=\"nl\")\n",
    "\n",
    "    # Set dimensions of dataset\n",
    "    N, d = X.shape\n",
    "\n",
    "    if fit_intercept:\n",
    "        # Add another column of constants to be the bias/intercept term\n",
    "        X_bias = np.hstack([np.ones((N, 1)), X])\n",
    "\n",
    "    # Initialize Optimisation Model\n",
    "    model = pyo.ConcreteModel()\n",
    "\n",
    "    # Define decision variables (linear regression coefficients and intercept)\n",
    "    model.w = pyo.Var(range(d+1), domain=pyo.Reals)\n",
    "\n",
    "    # Objective\n",
    "    model.obj = pyo.Objective(\n",
    "        expr=sum((y[i] - sum(X_bias[i, j] * model.w[j] for j in range(d + 1)))**2 for i in range(N))\n",
    "        + alpha * sum(model.w[j] ** 2 for j in range(1, d + 1)),  # Exclude the intercept term\n",
    "      sense=pyo.minimize\n",
    "    )\n",
    "\n",
    "    # Solve the model\n",
    "    results = solver.solve(model)\n",
    "\n",
    "    # Print the results\n",
    "    if results.solver.status == pyo.SolverStatus.ok and results.solver.termination_condition == pyo.TerminationCondition.optimal:\n",
    "        # Extracting coefficients\n",
    "        coefficients = [round(model.w[i].value, 2) for i in range(d+1)]\n",
    "\n",
    "        print(\"Solved! ðŸŽ‰\")\n",
    "        print(\"Solver Coefficients:\", coefficients)\n",
    "\n",
    "        # Print regression formula\n",
    "        formula = \"y = {}\".format(coefficients[0]) + \" + \" + \" + \".join(\"{}*x{}\".format(coeff, idx) for idx, coeff in enumerate(coefficients[1:], 1))\n",
    "        print(\"\")\n",
    "        print(\"Regression Formula:\", formula)\n",
    "\n",
    "    else:\n",
    "        print(\"Solver did not converge!\")\n",
    "\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0105ae-053c-46f2-859b-7ee1e9ed5e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved! ðŸŽ‰\n",
      "Solver Coefficients: [152.13, 19.81, -0.92, 75.42, 55.03, 19.92, 13.95, -47.55, 48.26, 70.14, 44.21]\n",
      "\n",
      "Regression Formula: y = 152.13 + 19.81*x1 + -0.92*x2 + 75.42*x3 + 55.03*x4 + 19.92*x5 + 13.95*x6 + -47.55*x7 + 48.26*x8 + 70.14*x9 + 44.21*x10\n"
     ]
    }
   ],
   "source": [
    "solver_ridge_coeffs = solver_ridge(X, y, \"ipopt\", alpha=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7730c08-21eb-49f0-9895-ed00c684b4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scikit-learn Coefficients: [152.13, 19.81, -0.92, 75.42, 55.03, 19.92, 13.95, -47.55, 48.26, 70.14, 44.21]\n"
     ]
    }
   ],
   "source": [
    "# Fit ridge model using scikit-learn for comparison\n",
    "ridge_reg = Ridge(alpha=10, fit_intercept=True)\n",
    "ridge_reg.fit(X, y)\n",
    "sklearn_ridge_coeffs = [round(ridge_reg.intercept_, 2)] + [round(coef, 2) for coef in ridge_reg.coef_]\n",
    "print(\"\\nScikit-learn Coefficients:\", sklearn_ridge_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb15ab8-9e5c-4f48-9183-3a9a5f9acc37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(solver_ridge_coeffs == sklearn_ridge_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb08d8e-0436-41e3-a6fd-a436c23fccae",
   "metadata": {},
   "source": [
    "# Model 3: Sparse Robust Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f7695dc-7e82-4565-a697-3f3127d6e360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def solver_sparse_ridge(X, y, max_non_zero, solver, alpha=1, fit_intercept=True):\n",
    "    \n",
    "    # Intialise the solver\n",
    "    solver = pyo.SolverFactory(solver)\n",
    "\n",
    "    # Set dimensions of dataset\n",
    "    N, d = X.shape\n",
    "\n",
    "    # Add another column of constants to be the bias/intercept term\n",
    "    if fit_intercept:\n",
    "        X = np.hstack([np.ones((N, 1)), X])\n",
    "\n",
    "    K = max_non_zero\n",
    "    M = 1e6  # Big M value\n",
    "\n",
    "    # Create the model\n",
    "    model = pyo.ConcreteModel()\n",
    "\n",
    "    # Variables\n",
    "    model.beta = pyo.Var(range(d+1), within=pyo.Reals)  # Regression coefficients\n",
    "    model.z = pyo.Var(range(d+1), within=pyo.Binary)  # Binary variables to enforce sparsity\n",
    "\n",
    "    # Objective function: Minimize the sum of squared errors + L2 penalty\n",
    "    model.obj = pyo.Objective(\n",
    "        expr=sum((y[i] - sum(X[i][j] * model.beta[j] for j in range(d+1)))**2 for i in range(N))\n",
    "            + alpha * sum(model.beta[j]**2 for j in range(1, d+1)),  # L2 penalty term starts from 1\n",
    "        sense=pyo.minimize\n",
    "    )\n",
    "\n",
    "    # Constraints\n",
    "    model.sparse_const = pyo.Constraint(expr=sum(model.z[j] for j in range(1, d+1)) <= K)  # Excludes the constant\n",
    "\n",
    "    # Big M constraints to enforce sparsity\n",
    "    model.positive_bigM = pyo.ConstraintList()\n",
    "    model.negative_bigM = pyo.ConstraintList()\n",
    "    for j in range(1, d+1):  # Starts from 1 to exclude the constant\n",
    "        model.positive_bigM.add(expr=model.beta[j] <= M * model.z[j])\n",
    "        model.negative_bigM.add(expr=model.beta[j] >= -M * model.z[j])\n",
    "\n",
    "    # Solve the model\n",
    "    results = solver.solve(model)\n",
    "\n",
    "    # Print the results\n",
    "    if results.solver.status == pyo.SolverStatus.ok and results.solver.termination_condition == pyo.TerminationCondition.optimal:\n",
    "        # Extracting coefficients\n",
    "        coefficients = [round(model.beta[i].value, 2) for i in range(d)]\n",
    "\n",
    "        print(\"Solved! ðŸŽ‰\")\n",
    "        print(\"Solver Coefficients:\", coefficients)\n",
    "\n",
    "        # Print regression formula\n",
    "        formula = \"y = {}\".format(coefficients[0]) + \" + \" + \" + \".join(\"{}*x{}\".format(coeff, idx) for idx, coeff in enumerate(coefficients[1:], 1))\n",
    "        print(\"\")\n",
    "        print(\"Regression Formula:\", formula)\n",
    "\n",
    "    else:\n",
    "        print(\"Solver did not converge!\")\n",
    "\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efa9d7ef-fdfe-4dcb-a927-a3187b284583",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved! ðŸŽ‰\n",
      "Solver Coefficients: [152.13, -0.0, 0.0, 392.04, -0.0, 0.0, -0.0, -0.0, -0.0, 370.61]\n",
      "\n",
      "Regression Formula: y = 152.13 + -0.0*x1 + 0.0*x2 + 392.04*x3 + -0.0*x4 + 0.0*x5 + -0.0*x6 + -0.0*x7 + -0.0*x8 + 370.61*x9\n"
     ]
    }
   ],
   "source": [
    "sparse_ridge_coeffs = solver_sparse_ridge(X, y, 2, \"bonmin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bc90e80-9903-458a-b768-02b9f4409d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero coefficients: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of non-zero coefficients: {np.sum(np.array(sparse_ridge_coeffs[1:]) >  0)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
